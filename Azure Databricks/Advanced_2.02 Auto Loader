*********** Using CloudFiles

files = dbutils.fs.ls(gym_mac_logs)

schema = spark.read.json(files[0].path).schema

def load_gym_logs():
    (spark.readStream.format("cloudFiles")
        .option("cloudFiles.format", "json")
        .schema(schema)
        .load(gym_mac_logs)
        .writeStream
        .format("delta")
        .option("checkpointLocation", Paths.gymMacLogsCheckpoint)
        .trigger(once=True)
        .option("path", Paths.gymMacLogs)
        .table("gym_mac_logs")
        .awaitTermination())
