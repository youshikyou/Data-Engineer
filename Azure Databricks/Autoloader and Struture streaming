******************Configure Streaming Read******************
This lab uses a collection of customer-related CSV data from DBFS found in /databricks-datasets/retail-org/customers/.
Read this data using Auto Loader using its schema inference (use customers_checkpoint_path to store the schema info).
Create a streaming temporary view called customers_raw_temp.


customers_checkpoint_path = f"{DA.paths.checkpoints}/customers"

(spark
  .readStream
  .format("cloudFiles")
  .option("cloudFiles.format","csv")
  .option("cloudFiles.schemalocation",customers_checkpoint_path)
  .load("/databricks-datasets/retail-org/customers/")
  .createOrReplaceTempView("customers_raw_temp"))
  
  
******************Write aggregated data to a Delta table******************
customers_count_checkpoint_path = f"{DA.paths.checkpoints}/customers_count"

query = (spark.table("customer_count_by_state_temp")
         .writeStream
         .format("delta")
         .option("checkpointLocation",customers_checkpoint_path)
         .outputMode("complete")
         .table("customer_count_by_state")
        )
